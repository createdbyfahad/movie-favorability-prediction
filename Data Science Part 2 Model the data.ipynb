{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<center>\n",
    "Data Science Part 2: Model The Data\n",
    "</center>\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "By Fahad Alarefi. The purpose of this three-part project is to use machine learning into making use of a publicaly available table called IMDB 5000 titles.\n",
    "The main idea is to come up with a function which can predictate, with high accuracy, whether a provided movie data will have 8 stars or more by the user community. The technique of decision trees will be used.\n",
    "The dataset is accessed from here:\n",
    "https://data.world/data-society/imdb-5000-movie-dataset\n",
    "\n",
    "</div>\n",
    "<br />\n",
    "<div class=h1_cell>\n",
    "In this part, we will continue from the last part (Part1: wrangle the data), and model the table.\n",
    "Modeling the data means to use the data to produce a prediction model based on it's input.\n",
    "We will use two models of prediction: Random Forest and Decision Trees. And then compare thier results. <br/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Read the dataset from a last module\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "First step,\n",
    "get the dataset from the last module we worked on.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if os.path.isfile('./part1_movie_table.csv'):\n",
    "    file_name = 'part1_movie_table.csv'\n",
    "else:\n",
    "    file_name = 'https://github.com/createdbyfahad/datascience/files/2593719/part1_movie_table.txt'\n",
    "\n",
    "\n",
    "movie_table = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, in order not to rewrite the previous functions in last module, I have created a python file\n",
    "<br/>that has all needed functions.\n",
    "<br />So, here we will import it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "\n",
    "%who function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Step 1: More wrangling\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "In the last section, we did some data filling using kmeans on columns budget and gross.\n",
    "<br /> Now, we will make use of the budget and gross by seperating them into three buckets (high, med, low)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_names = ['low', 'medium', 'high']\n",
    "movie_table['budget_bin'] = pd.qcut(movie_table['kmeans_budget'], 3, labels=bin_names)\n",
    "one_hot_budget = pd.get_dummies(movie_table['budget_bin'],prefix='budget',dummy_na=False)  # false because should not have empties\n",
    "movie_table = movie_table.join(one_hot_budget)\n",
    "\n",
    "movie_table['gross_bin'] = pd.qcut(movie_table['kmeans_gross'], 3, labels=bin_names)\n",
    "one_hot_gross = pd.get_dummies(movie_table['gross_bin'],prefix='gross',dummy_na=False)  # false because should not have empties\n",
    "movie_table = movie_table.join(one_hot_gross)\n",
    "\n",
    "movie_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in order to produce same results, everytime this notebook used, for the random forests, we will use seeder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seeder(seed):\n",
    "    z = [seed]  # why embed in list? See https://stackoverflow.com/a/4851555\n",
    "    def f():\n",
    "        val = z[0]\n",
    "        z[0] += 1\n",
    "        return val\n",
    "    return f\n",
    "\n",
    "new_seed = seeder(100)# new_seed is a function that will return a sequence of ints, one on each new call\n",
    "\n",
    "import random\n",
    "random.seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Method 1: Random Forests\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "In this section, we will try the random forests and register it's results as a column in the table <br/><br />\n",
    "\n",
    "We will create a variable that has the column we want to predict on (is_good), which, if you don't remember, has value 1 if imdb_score is => 8\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'is_good'\n",
    "#movie_table = movie_table[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the implementation of random forests (source: Stephen Ficaks, University of Oregon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "def forest_builder(table, column_choices, target, hypers):\n",
    "    tree_n = 5 if 'total-trees' not in hypers else hypers['total-trees']\n",
    "    m = int(len(column_choices)**.5) if 'm' not in hypers else hypers['m']\n",
    "    k = hypers['max-depth'] if 'max-depth' in hypers else min(2, len(column_choices))\n",
    "    gig_cutoff = hypers['gig-cutoff'] if 'gig-cutoff' in hypers else 0.0\n",
    "\n",
    "    #build a single tree - call it multiple times to build multiple trees\n",
    "    def iterative_build(k):\n",
    "        train = table.sample(frac=1.0, replace=True, random_state=new_seed())\n",
    "        train = train.reset_index()\n",
    "        left_out = table.loc[~table.index.isin(train['index'])]\n",
    "        left_out = left_out.reset_index() # this gives us the old index in its own column\n",
    "        oob_list = left_out['index'].tolist()  # list of row indices from original titanic table\n",
    "        \n",
    "        rcols = random.sample(column_choices, m)  # subspcace sampling\n",
    "        columns_sorted = find_best_splitter(train, rcols, target)\n",
    "        (best_column, gig_value) = columns_sorted[0]\n",
    "\n",
    "        #Note I add _1 or _0 to make it more readable for debugging\n",
    "        current_paths = [{'conjunction': [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                          'prediction': None,\n",
    "                          'gig_score': gig_value},\n",
    "                         {'conjunction': [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                          'prediction': None,\n",
    "                          'gig_score': gig_value}\n",
    "                        ]\n",
    "        k -= 1  # we just built a level as seed so subtract 1 from k\n",
    "        tree_paths = []  # add completed paths here\n",
    "\n",
    "        while k>0:\n",
    "            new_paths = []\n",
    "            for path in current_paths:\n",
    "                conjunct = path['conjunction']  # a list of (name, lambda)\n",
    "                before_table = generate_table(train, conjunct)  #the subtable the current conjunct leads to\n",
    "                rcols = random.sample(column_choices, m)  # subspace\n",
    "                columns_sorted = find_best_splitter(before_table, rcols, target)\n",
    "                (best_column, gig_value) = columns_sorted[0]\n",
    "                if gig_value > gig_cutoff:\n",
    "                    new_path_1 = {'conjunction': conjunct + [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                                'prediction': None,\n",
    "                                 'gig_score': gig_value}\n",
    "                    new_paths.append( new_path_1 ) #true\n",
    "                    new_path_0 = {'conjunction': conjunct + [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                                'prediction': None,\n",
    "                                 'gig_score': gig_value\n",
    "                                 }\n",
    "                    new_paths.append( new_path_0 ) #false\n",
    "                else:\n",
    "                    #not worth splitting so complete the path with a prediction\n",
    "                    path['prediction'] = compute_prediction(before_table, target)\n",
    "                    tree_paths.append(path)\n",
    "            #end for loop\n",
    "\n",
    "            current_paths = new_paths\n",
    "            if current_paths != []:\n",
    "                k -= 1\n",
    "            else:\n",
    "                break  # nothing left to extend so have copied all paths to tree_paths\n",
    "        #end while loop\n",
    "\n",
    "        #Generate predictions for all paths that have None\n",
    "        for path in current_paths:\n",
    "            conjunct = path['conjunction']\n",
    "            before_table = generate_table(train, conjunct)\n",
    "            path['prediction'] = compute_prediction(before_table, target)\n",
    "            tree_paths.append(path)\n",
    "        return (tree_paths, oob_list)\n",
    "    \n",
    "    #let's build the forest\n",
    "    forest = []\n",
    "    for i in range(tree_n):\n",
    "        (paths, oob) = iterative_build(k)\n",
    "        forest.append({'paths': paths, 'weight': None, 'oob': oob})\n",
    "        \n",
    "    return forest\n",
    "\n",
    "def vote_taker(row, forest):\n",
    "    votes = {0:0, 1:0}\n",
    "    for tree in forest:\n",
    "        prediction = tree_predictor(row, tree)\n",
    "        votes[prediction] += 1\n",
    "    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\n",
    "    return winner\n",
    "\n",
    "def find_best_splitter(table, choice_list, target):\n",
    "    gig_scores = map(lambda col: (col, gig(table, col, target)), choice_list)\n",
    "    gig_sorted = sorted(gig_scores, key=lambda item: item[1], reverse=True)\n",
    "    return gig_sorted\n",
    "\n",
    "def probabilities(counts):\n",
    "    count_0 = 0 if 0 not in counts else counts[0]  #could have no 0 values\n",
    "    count_1 = 0 if 1 not in counts else counts[1]\n",
    "    total = count_0 + count_1\n",
    "    probs = (0,0) if total == 0 else (1.0*count_0/total, 1.0*count_1/total)  #build 2-tuple\n",
    "    return probs\n",
    "\n",
    "def gini(counts):\n",
    "    (p0,p1) = probabilities(counts)\n",
    "    sum_probs = p0**2 + p1**2\n",
    "    gini = 1 - sum_probs\n",
    "    return gini\n",
    "\n",
    "def gig(starting_table, split_column, target_column):\n",
    "    \n",
    "    #split into two branches, i.e., two sub-tables\n",
    "    true_table = starting_table.loc[starting_table[split_column] == 1]\n",
    "    false_table = starting_table.loc[starting_table[split_column] == 0]\n",
    "    \n",
    "    #Now see how the target column is divided up in each sub-table (and the starting table)\n",
    "    true_counts = true_table[target_column].value_counts()  # Note using true_table and not titanic_table\n",
    "    false_counts = false_table[target_column].value_counts()  # Note using true_table and not titanic_table\n",
    "    starting_counts = starting_table[target_column].value_counts() \n",
    "    \n",
    "    #compute the gini impurity for the 3 tables\n",
    "    starting_gini = gini(starting_counts)\n",
    "    true_gini = gini(true_counts)\n",
    "    false_gini = gini(false_counts)\n",
    "\n",
    "    #compute the weights\n",
    "    starting_size = len(starting_table.index)\n",
    "    true_weight = 0.0 if starting_size == 0 else 1.0*len(true_table.index)/starting_size\n",
    "    false_weight = 0.0 if starting_size == 0 else 1.0*len(false_table.index)/starting_size\n",
    "    \n",
    "    #wrap it up and put on a bow\n",
    "    gig = starting_gini - (true_weight * true_gini + false_weight * false_gini)\n",
    "    \n",
    "    return gig\n",
    "\n",
    "def build_pred(column, branch):\n",
    "    return lambda row: row[column] == branch\n",
    "\n",
    "def generate_table(table, conjunct):\n",
    "    result_table = functools.reduce(lambda accum, pair: accum.loc[pair[1]], conjunct, table)  # accum starts as table\n",
    "    return result_table\n",
    "\n",
    "def compute_prediction(table, target):\n",
    "    counts = table[target].value_counts()  # counts looks like {0: v1, 1: v2}\n",
    "    if 0 not in counts and 1 not in counts:\n",
    "        raise LookupError('Prediction impossible - Empty tree on leaf')\n",
    "    if 0 not in counts:\n",
    "        prediction = 1\n",
    "    elif 1 not in counts:\n",
    "        prediction = 0\n",
    "    elif counts[1] > counts[0]:  # ties go to 0 (negative)\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = 0\n",
    "\n",
    "    return prediction\n",
    "\n",
    "def tree_predictor(row, tree):\n",
    "    \n",
    "    #go through each path, one by one (could use a map instead of for loop?)\n",
    "    for path in tree['paths']:\n",
    "        conjuncts = path['conjunction']\n",
    "        result = map(lambda tuple: tuple[1](row), conjuncts)\n",
    "        if all(result):\n",
    "            return path['prediction']\n",
    "    raise LookupError('No true paths found for row: ' + str(row))\n",
    "\n",
    "def predictor_case(row, pred, target):\n",
    "    actual = row[target]\n",
    "    prediction = row[pred]\n",
    "    if actual == 0 and prediction == 0:\n",
    "        case = 'true_negative'\n",
    "    elif actual == 1 and prediction == 1:\n",
    "        case = 'true_positive'\n",
    "    elif actual == 1 and prediction == 0:\n",
    "        case = 'false_negative'\n",
    "    else:\n",
    "        case = 'false_positive'\n",
    "    return case\n",
    "\n",
    "def f1(cases):\n",
    "    dict_cases = cases.to_dict()  # easier to work with dict than series\n",
    "    #the heart of the matrix\n",
    "    tp = 0 if 'true_positive' not in dict_cases else dict_cases['true_positive']  # use isin method if working with Series\n",
    "    fn = 0 if 'false_negative' not in dict_cases else dict_cases['false_negative']\n",
    "    tn = 0 if 'true_negative' not in dict_cases else dict_cases['true_negative']\n",
    "    fp = 0 if 'false_positive' not in dict_cases else dict_cases['false_positive']\n",
    "    total_pos = tp+fn\n",
    "    total_pos_predict = tp+fp\n",
    "    \n",
    "    #other measures we can derive\n",
    "    recall = 0.0 if total_pos == 0 else 1.0*tp/total_pos  # positive correct divided by total positive in the table\n",
    "    precision = 0.0 if total_pos_predict == 0 else 1.0*tp/total_pos_predict # positive correct divided by all positive predictions made\n",
    "    recall_div = 0.0 if recall == 0 else 1.0/recall\n",
    "    precision_div = 0.0 if precision == 0 else 1.0/precision\n",
    "    sum_f1 = recall_div + precision_div\n",
    "    f1 = 0.0 if sum_f1 == 0 else 2.0/sum_f1\n",
    "    return f1\n",
    "\n",
    "def informedness(cases):\n",
    "    dict_cases = cases.to_dict()  # easier to work with dict than series\n",
    "    tp = 0 if 'true_positive' not in dict_cases else dict_cases['true_positive']\n",
    "    fn = 0 if 'false_negative' not in dict_cases else dict_cases['false_negative']\n",
    "    tn = 0 if 'true_negative' not in dict_cases else dict_cases['true_negative']\n",
    "    fp = 0 if 'false_positive' not in dict_cases else dict_cases['false_positive']\n",
    "    total_pos = tp+fn\n",
    "    total_neg = tn+fp\n",
    "\n",
    "    recall = 0.0 if total_pos == 0 else 1.0*tp/total_pos  # positive correct divided by total positive in the table\n",
    "    specificty = 0.0 if total_neg == 0 else 1.0*tn/total_neg # negative correct divided by total negative in the table\n",
    "    J = (recall + specificty) - 1\n",
    "    return J\n",
    "\n",
    "def accuracy(cases):\n",
    "    dict_cases = cases.to_dict()\n",
    "    tp = 0 if 'true_positive' not in dict_cases else dict_cases['true_positive']\n",
    "    fn = 0 if 'false_negative' not in dict_cases else dict_cases['false_negative']\n",
    "    tn = 0 if 'true_negative' not in dict_cases else dict_cases['true_negative']\n",
    "    fp = 0 if 'false_positive' not in dict_cases else dict_cases['false_positive']\n",
    "\n",
    "    return 1.0*(tp + tn)/(tp+tn+fp+fn)  #assumes at least one case exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, here are simple functions that will execute the random forest (rf), and test it's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_rf(ref, table, column_choices, target, hypers):\n",
    "    forest = forest_builder(table, column_choices, target, hypers=hypers)\n",
    "    table['forest_'+str(ref)] = table.apply(lambda row: vote_taker(row, forest), axis=1)\n",
    "    table['forest_'+str(ref)+'_type'] = table.apply(lambda row: predictor_case(row, pred='forest_'+str(ref), target=target), axis=1)\n",
    "    return (table, forest)\n",
    "\n",
    "def test_rf(ref, table):\n",
    "    forest_types = table['forest_'+str(ref)+'_type'].value_counts()  # returns a series\n",
    "    return (accuracy(forest_types), f1(forest_types), informedness(forest_types))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try doing rf on the sample table we produced earlier.<br />\n",
    "Splitter_columns are those who have values of 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter_columns = [ u'Action', u'Adventure',\n",
    "       u'Animation', u'Biography', u'Comedy', u'Crime', u'Documentary',\n",
    "       u'Drama', u'Family', u'Fantasy', u'Film-Noir', u'History', u'Horror',\n",
    "       u'Music', u'Musical', u'Mystery', u'News', u'Romance', u'Sci-Fi',\n",
    "       u'Sport', u'Thriller', u'War', u'Western', u'c_Afghanistan',\n",
    "       u'c_Argentina', u'c_Aruba', u'c_Australia', u'c_Bahamas', u'c_Belgium',\n",
    "       u'c_Brazil', u'c_Bulgaria', u'c_Cameroon', u'c_Canada', u'c_Chile',\n",
    "       u'c_China', u'c_Colombia', u'c_Czech Republic', u'c_Denmark',\n",
    "       u'c_Dominican Republic', u'c_Egypt', u'c_Finland', u'c_France',\n",
    "       u'c_Georgia', u'c_Germany', u'c_Greece', u'c_Hong Kong', u'c_Hungary',\n",
    "       u'c_Iceland', u'c_India', u'c_Indonesia', u'c_Iran', u'c_Ireland',\n",
    "       u'c_Israel', u'c_Italy', u'c_Japan', u'c_Kyrgyzstan', u'c_Mexico',\n",
    "       u'c_Netherlands', u'c_New Line', u'c_New Zealand', u'c_Norway',\n",
    "       u'c_Official site', u'c_Panama', u'c_Peru', u'c_Philippines',\n",
    "       u'c_Poland', u'c_Romania', u'c_Russia', u'c_Slovakia',\n",
    "       u'c_South Africa', u'c_South Korea', u'c_Spain', u'c_Sweden',\n",
    "       u'c_Taiwan', u'c_Thailand', u'c_UK', u'c_USA', u'c_West Germany',\n",
    "       u'rating_NC-17', u'rating_PG', u'rating_PG-13', u'rating_R',\n",
    "       u'rating_Unrated', 'budget_low', 'is_new', 'is_long',\n",
    "        'budget_medium', 'budget_high', 'gross_low', 'gross_medium', 'gross_high']\n",
    "       \n",
    "(movie_table, forest0) = execute_rf(0, movie_table, splitter_columns, target_column, {})\n",
    "print(test_rf(0, movie_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see, this result produced very bad f1 and informedness values (both 0.0) which means that our predictor is not accurate. <br /> It might be because we have very small amount of movies with score of 8 or more.<br/>\n",
    "So we will look for the median score for movies and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movie_table['imdb_score'].median())\n",
    "print(len(movie_table[movie_table['imdb_score'] >= 8.0]))\n",
    "print(len(movie_table[movie_table['imdb_score'] >= 6.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median is 6.5, and as you see the amount movies with 8 or more is very low. So we will do another test for imdb_scores that are 6.5 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table['is_good2'] = movie_table.apply(lambda row: 1 if row.imdb_score >= 6.5 else 0, axis=1) # tried 7.5, 8\n",
    "target_column = \"is_good2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we will redo our tests and compare them.<br />\n",
    "My naming technique is the first two digits is for amount of trees, and remaining for max-depth.<br />\n",
    "First, we will try on three tree sizes 5, 11, 13<br />\n",
    "And will test our results using Out-of-bag technique. In detail, our random forests function had produced an oob rows <br /> for each tree it produced. So know will get to use those \"left-out\" rows into testing our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_taker_oob(row, forest):\n",
    "    votes = {0:0, 1:0}\n",
    "    for tree in forest:\n",
    "        if row['index'] in tree['oob']:\n",
    "            prediction = tree_predictor(row, tree)\n",
    "            votes[prediction] += 1\n",
    "    winner = 1 if votes[1]>votes[0] else 0  #ties go to 0\n",
    "    return winner\n",
    "\n",
    "def oob_testing(table, forest):\n",
    "    \n",
    "    #first create a union of oobs\n",
    "    oob_df = pd.DataFrame(columns=table.columns)\n",
    "    for tree in forest:\n",
    "        oob_df = oob_df.append([table.loc[[x]] for x in tree['oob'] if x not in oob_df.index])\n",
    "    \n",
    "    #create a new index column\n",
    "    oob_df = oob_df.reset_index()\n",
    "    \n",
    "    return oob_df\n",
    "    #for each tree\n",
    "\n",
    "#total of the oobs in the forest\n",
    "def total_oob(forest):\n",
    "    total = 0\n",
    "    for tree in forest:\n",
    "        total += len(tree['oob'])\n",
    "    return total\n",
    "\n",
    "def list_oob(forest):\n",
    "    oob = []\n",
    "    for tree in forest:\n",
    "        oob.extend(tree['oob'])\n",
    "    return oob\n",
    "\n",
    "def test_oob(table, forest, target):\n",
    "    oob = oob_testing(table, forest)\n",
    "    oob['forest_oob'] = oob.apply(lambda row: vote_taker_oob(row, forest), axis=1)\n",
    "    oob['forest_oob_type'] = oob.apply(lambda row: predictor_case(row, pred='forest_oob', target=target), axis=1)\n",
    "    forest_oob_types = oob['forest_oob_type'].value_counts()\n",
    "    #print(forest_oob_types.sum())  # length of testing table\n",
    "    return (accuracy(forest_oob_types), f1(forest_oob_types), informedness(forest_oob_types))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(movie_table, forest052) = execute_rf('052', movie_table, splitter_columns, target_column, {})\n",
    "print(test_oob(movie_table, forest052, target_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(movie_table, forest112) = execute_rf(112, movie_table, splitter_columns, target_column, {'total-trees':11})\n",
    "print(test_oob(movie_table, forest112, target_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(movie_table, forest132) = execute_rf(132, movie_table, splitter_columns, target_column, {'total-trees':13})\n",
    "print(test_oob(movie_table, forest132, target_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(at the time of this test) The 13 trees forest has the best scores, so we will continue with it and try two different max-depth values: 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(movie_table, forest133) = execute_rf(133, movie_table, splitter_columns, target_column, {'total-trees':13, 'max-depth':3})\n",
    "print(test_oob(movie_table, forest133, target_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(movie_table, forest134) = execute_rf(134, movie_table, splitter_columns, target_column, {'total-trees':13, 'max-depth':4})\n",
    "print(test_oob(movie_table, forest134, target_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(at the time of the test) Looks like the test with max-depth 4 had the best results. So we will stick with the it. <br />\n",
    "Next, we try using the Decision Tree method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Method 2: Decision Trees\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "In this section, we will try decision trees method and register it's results as a column in the table <br/><br />\n",
    "\n",
    "We will continue from the last part, and try to predictate whether a movie will have a more 6.5 or more score in IMDB or not. <br />\n",
    "Here are some functions for decision tree impementation (source: Stephen Ficaks, University of Oregon)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree_iter(table, choices, target, hypers={} ):\n",
    "\n",
    "    k = hypers['max-depth'] if 'max-depth' in hypers else min(4, len(choices))\n",
    "    gig_cutoff = hypers['gig-cutoff'] if 'gig-cutoff' in hypers else 0.0\n",
    "    \n",
    "    def iterative_build(k):\n",
    "        columns_sorted = find_best_splitter(table, choices, target)\n",
    "        (best_column, gig_value) = columns_sorted[0]\n",
    "        \n",
    "        #Note I add _1 or _0 to make it more readable for debugging\n",
    "        current_paths = [{'conjunction': [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                          'prediction': None,\n",
    "                          'gig_score': gig_value},\n",
    "                         {'conjunction': [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                          'prediction': None,\n",
    "                          'gig_score': gig_value}\n",
    "                        ]\n",
    "        k -= 1  # we just built a level as seed so subtract 1 from k\n",
    "        tree_paths = []  # add completed paths here\n",
    "        \n",
    "        while k>0:\n",
    "            new_paths = []\n",
    "            for path in current_paths:\n",
    "                conjunct = path['conjunction']  # a list of (name, lambda)\n",
    "                before_table = generate_table(table, conjunct)  #the subtable the current conjunct leads to\n",
    "                columns_sorted = find_best_splitter(before_table, choices, target)\n",
    "                (best_column, gig_value) = columns_sorted[0]\n",
    "                if gig_value > gig_cutoff:\n",
    "                    new_path_1 = {'conjunction': conjunct + [(best_column+'_1', build_pred(best_column, 1))],\n",
    "                                'prediction': None,\n",
    "                                 'gig_score': gig_value}\n",
    "                    new_paths.append( new_path_1 ) #true\n",
    "                    new_path_0 = {'conjunction': conjunct + [(best_column+'_0', build_pred(best_column, 0))],\n",
    "                                'prediction': None,\n",
    "                                 'gig_score': gig_value}\n",
    "                    new_paths.append( new_path_0 ) #false\n",
    "                else:\n",
    "                    #not worth splitting so complete the path with a prediction\n",
    "                    path['prediction'] = compute_prediction(before_table, target)\n",
    "                    tree_paths.append(path)\n",
    "            #end for loop\n",
    "            \n",
    "            current_paths = new_paths\n",
    "            if current_paths != []:\n",
    "                k -= 1\n",
    "            else:\n",
    "                break  # nothing left to extend so have copied all paths to tree_paths\n",
    "        #end while loop\n",
    "\n",
    "        #Generate predictions for all paths that have None\n",
    "        for path in current_paths:\n",
    "            conjunct = path['conjunction']\n",
    "            before_table = generate_table(table, conjunct)\n",
    "            path['prediction'] = compute_prediction(before_table, target)\n",
    "            tree_paths.append(path)\n",
    "        return tree_paths\n",
    "\n",
    "    return {'paths': iterative_build(k), 'weight': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we will create some functions that will help making this process easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_dt(ref, table, column_choices, target, hypers):\n",
    "    tree = build_tree_iter(table, column_choices, target, hypers)\n",
    "    table['tree_'+str(ref)] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\n",
    "    table['tree_'+str(ref)+'_type'] = table.apply(lambda row: predictor_case(row, pred='tree_'+str(ref), target=target), axis=1)\n",
    "    return table\n",
    "\n",
    "def test_dt(ref, table):\n",
    "    tree_types = table['tree_'+str(ref)+'_type'].value_counts()  # returns a series\n",
    "    return (accuracy(tree_types), f1(tree_types), informedness(tree_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table = execute_dt(0, movie_table, splitter_columns, target_column, {'max-depth':2})\n",
    "print(test_dt(0, movie_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That produced good results, but we want to change the way we test our trees and use K-folds.\n",
    "<br />Which will seperate the dataset into k slices, then train on k-1 slices, and test on the last slide. <br/>Do this process k times, so that every slice has been a test slice for once.<br />\n",
    "We will choose k to be 5 and test two trees with max-depth of 2 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_training(slices, left_out):\n",
    "    training_slices = []\n",
    "    for i in range(len(slices)):\n",
    "        if i == left_out:\n",
    "            continue\n",
    "        training_slices.append(slices[i])\n",
    "    return pd.concat(training_slices)  # note we are returning a table (DataFrame)\n",
    "\n",
    "def caser(table, tree, target):\n",
    "    scratch_table = pd.DataFrame(columns=['prediction', 'actual'])\n",
    "    scratch_table['prediction'] = table.apply(lambda row: tree_predictor(row, tree), axis=1)\n",
    "    scratch_table['actual'] = table[target]  # just copy the target column\n",
    "    cases = scratch_table.apply(lambda row: predictor_case(row, pred='prediction', target='actual'), axis=1)\n",
    "    return cases.value_counts()\n",
    "\n",
    "def k_fold_random(table, k, target, hypers, candidate_columns):\n",
    "    result_columns = ['name', 'true_positive', 'false_positive', 'true_negative', 'false_negative', 'accuracy', 'f1', 'informedness']\n",
    "    k_fold_results_table = pd.DataFrame(columns=result_columns)\n",
    "\n",
    "    total_len = len(table.index)\n",
    "    split_size = int(total_len/(1.0*k))\n",
    "    slices = [pd.DataFrame(columns=table.columns) for x in range(k)]\n",
    "\n",
    "    #generate the slices\n",
    "    for ind in range(total_len):\n",
    "        rand = random.randint(0,k-1)\n",
    "        slices[rand] = slices[rand].append(table.loc[[ind]])\n",
    "    \n",
    "    #generate test results\n",
    "    for i in range(k):\n",
    "        test_table = slices[i]\n",
    "        train_table = compute_training(slices, i)\n",
    "        fold_tree = build_tree_iter(train_table, candidate_columns, target, hypers)  # train\n",
    "        fold_cases = caser(test_table, fold_tree, target)  # test\n",
    "\n",
    "        k_fold_results_table = k_fold_results_table.append(fold_cases,ignore_index=True)\n",
    "        end = k_fold_results_table.last_valid_index()\n",
    "        k_fold_results_table.loc[end, 'name'] =  'fold '+str(i+1)+' test'\n",
    "        k_fold_results_table.loc[end, 'accuracy'] =  accuracy(fold_cases)\n",
    "        k_fold_results_table.loc[end, 'f1'] =  f1(fold_cases)\n",
    "        k_fold_results_table.loc[end, 'informedness'] =  informedness(fold_cases)\n",
    "        \n",
    "    k_fold_results_table.__doc__ = str(hypers)  # adds comment to remind me of hyper params used\n",
    "    return k_fold_results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth2_rand_table = k_fold_random(movie_table, 5, target_column, {'max-depth':2}, splitter_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(depth2_rand_table.describe().loc[['mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth4_rand_table = k_fold_random(movie_table, 5, target_column, {'max-depth':4}, splitter_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(depth4_rand_table.describe().loc[['mean']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the decision trees might have better accuracy then random forests (we will do additinal devlopment on dt). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Next Step\n",
    "</h1>\n",
    "<div class=h1_cell>\n",
    "Decision trees have produced better results than the random forests. So our next model is to fine-tune the random forests model. <br />\n",
    "By tuning it, we might come up with better performance by the model. Therefore, in the next model, we will work on the best rf model we came with (forest133) by receating it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "movie_table.to_csv(\"part2_movie_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pickle\n",
    "\n",
    "with open('rf', 'wb') as fp:\n",
    "    dill.dump(forest134, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
